{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "# import synthetic dataset generator\n",
    "import sys\n",
    "sys.path.insert(1, '..\\\\data\\\\raw')\n",
    "from synthetic_baumann import create_synth # copied from https://github.com/rcrupiISP/BiasOnDemand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('whitegrid')\n",
    "paper_rc = {'lines.linewidth': 1, 'lines.markersize': 7} \n",
    "sns.set_context(font_scale=1.4) # , rc=paper_rc, 'paper'\n",
    "\n",
    "font = {'family' : 'Times New Roman',\n",
    "        'size'   : 18}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output_wrapper, .output {\n",
       "    height:auto !important;\n",
       "    max-height:10000px;  /* your desired max-height here */\n",
       "}\n",
       ".output_scroll {\n",
       "    box-shadow:none !important;\n",
       "    webkit-box-shadow:none !important;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".output_wrapper, .output {\n",
    "    height:auto !important;\n",
    "    max-height:10000px;  /* your desired max-height here */\n",
    "}\n",
    ".output_scroll {\n",
    "    box-shadow:none !important;\n",
    "    webkit-box-shadow:none !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Fuzzy rough set model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume that we have a universe of discourse $U$, a fuzzy set $X \\subseteq U$ and a fuzzy binary relation $R \\subseteq U \\times U$ such that $\\mu_{X}(x)$ and $\\mu_{R}(y,x)$ are their membership functions, respectively. The membership function $\\mu_R : U \\rightarrow [0,1]$ determines the degree to which $x \\in U$ is a member of $X$, whereas $\\mu_R : U \\times U \\rightarrow [0,1]$ denotes the degree to which $y$ is considered to be a member of $X$ from the fact that $x$ is a member of the fuzzy set $X$. Whenever opportune, $R(x)$ is denoted with its membership function $\\mu_{R(x)}(y) = \\mu_{R}(y,x)$.\n",
    "\n",
    "Firstly, let us build a partition of $U$ according to the decision classes. The $X_{k}$ set contains all objects associated with the $k$-th decision class. The membership degree of $x \\in U$ to a subset $X_{k}$ was computed using the following hard membership function: $\\mu_{X_{k}}(x) = 1$ for $x \\in X_{k}$ and $\\mu_{X_{k}}(x) = 0$ for $x \\not\\in X_{k}$, as we assume that all problem instances are correctly labeled. \n",
    "\n",
    "Secondly, we define a fuzzy binary relation $\\mu_{R}(y,x)$ to determine the fuzzy similarity between instances $x$ and $y$. This function should combine the membership degree $\\mu_{X_{k}}(x)$ with the similarity degree $\\phi(x,y)$ between two objects $x, y \\in U$. Overall, we define $\\mu_{R}(y,x) = \\phi(x,y)$.\n",
    "\n",
    "The similarity degree is defined as\n",
    "\n",
    "$\\phi(x,y) = e^{-\\lambda \\big( d(x,y) \\big)}$\n",
    "\n",
    "where $\\lambda > 0$ is a user-specified smoothing parameter to avoid saturation problems in which similarity values have low variability even for quite dissimilar instances. $d$ is a user specified distance function which is defined in part 1.2 of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute fuzzy-rough sets we use the definition of Radzikowska & Kerre (2002, Definition 4) [1] who generalize the lower and upper approximation operators in a Pawlak approximation space. We use this fuzzy-rough set approach as defined in the work of D'eer et al. (2015). This definition is based on a conjunctor, an implicator and a binary fuzzy relation. Let $(U,R)$ be a *fuzzy approximation space*  that consists of a non-empty universe $U$ and a binary fuzzy relation $R$ on $U$. Let $A$ be a fuzzy set in $U$, $\\mathcal{I}$ an implicator and $\\mathcal{T}$ a conjunctor. The $(\\mathcal{I},\\mathcal{T})$-*fuzzy rough approximation* of $A$ by $R$ is the pair of fuzzy sets ($\\underline{\\rm \\text{apr}}^{\\mathcal{I}}_{R}(A)$,$\\overline{\\rm \\text{apr}}^{\\mathcal{I}}_{R}(A)$). For $x \\in U$:\n",
    "\n",
    " $(\\underline{\\rm \\text{apr}}^{\\mathcal{I}}_{R}(A))(x)=\\underset{y \\in U}{inf}\\mathcal{I}(R(y,x),A(y))$,  \n",
    " $(\\overline{\\rm \\text{apr}}^{\\mathcal{T}}_{R}(A))(x)=\\underset{y \\in U}{sup}\\mathcal{T}(R(y,x),A(y))$  \n",
    "\n",
    "Source:  \n",
    "[1] A.M. Radzikowska, E.E. Kerre, A comparative study of fuzzy rough sets, Fuzzy Sets and Systems 126, p. 137–156, 2002  \n",
    "[2] D'eer, L., Verbiest, N., Cornelis, C., & Godo, L. (2015). A comprehensive study of implicator–conjunctor-based and noise-tolerant fuzzy rough sets: definitions, properties and robustness analysis. Fuzzy Sets and Systems, 275, 1-38.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define the fuzzy rough regions using the upper and lower approximations. The membership functions for the fuzzy rough positive, negative and boundary regions can be defined as \n",
    "\n",
    "$\\mu_{POS(X_{k})}(x) = \\mu_{R_{*}(X_{k})}(x)$  \n",
    "$\\mu_{NEG(X_{k})}(x) = 1 - \\mu_{R^{*}(X_{k})}(x)$  \n",
    "$\\mu_{BND(X_{k})}(x) = \\mu_{R^{*}(X_{k})}(x) - \\mu_{R_{*}(X_{k})}(x)$  \n",
    "\n",
    "Membership values to positive regions indicate the extent to which the instances belong to a decision class, membership values to negative regions indicate the extent to which the instances do not belong to a decision class, whereas membership values to boundary regions indicate the extent to which the instances are uncertain to the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Similarity or distance function (HEOM, HMOM, HVDM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $F={f_{1},...,f{m}}$ be a set of features, where $f_{j}$ can be either numeric or nominal while $x(j)$ and $y(j)$ denote the values of the $j$-th feature according to instances $x$ and $y$, respectively. Thus, the dissimilarity between between two instances $x$ and $y$ can be computed as follows:\n",
    "\n",
    "**Heterogeneous Manhattan-Overlap Metric** (HMOM)\n",
    "\n",
    "$$d(x,y) =\\sum_{j=1}^{|F|}\\rho_{j}(x,y)$$    \n",
    "\n",
    "such that  \n",
    "    \n",
    "$$\\rho_{j}(x,y) = \n",
    "\\begin{cases}\n",
    "0\\qquad\\qquad\\qquad\\qquad if\\enspace f_{j} \\in F\\enspace is\\enspace nominal \\wedge x(j) = y(j)\\\\\n",
    "1\\qquad\\qquad\\qquad\\qquad  if\\enspace f_{j} \\in F\\enspace is\\enspace nominal \\wedge x(j) \\neq y(j)\\\\\n",
    "\\frac{|x(j) - y(j)|}{max_{j}-min_{j}}\\qquad \\qquad if\\enspace f_{j} \\in F\\enspace is\\enspace numeric\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Heterogeneous Euclidean-Overlap Metric** (HEOM)\n",
    "$$d(x,y) =\\sqrt{\\sum_{j=1}^{|F|}\\sigma_{j}(x,y)}$$\n",
    "    \n",
    "such that\n",
    "    \n",
    "$$\\sigma_{j}(x,y) = \\begin{cases}\n",
    "0\\qquad\\qquad\\qquad\\qquad if\\enspace f_{j} \\in F\\enspace is\\enspace nominal \\wedge x(j) = y(j)\\\\\n",
    "1\\qquad\\qquad\\qquad\\qquad  if\\enspace f_{j} \\in F\\enspace is\\enspace nominal \\wedge x(j) \\neq y(j)\\\\\n",
    "(\\frac{x(j) - y(j)}{max_{j}-min_{j}})^{2}\\qquad \\qquad if\\enspace f_{j} \\in F\\enspace is\\enspace numeric\n",
    "\\end{cases}$$\n",
    "\n",
    "**Heterogeneous Value Difference Metric** (HVDM)\n",
    "\n",
    "$$d(x,y) =\\sqrt{\\sum_{j=1}^{|F|}\\tau_{j}(x,y)}$$\n",
    "\n",
    "such that\n",
    "    \n",
    "$$\\tau_{j}(x,y) = \\begin{cases}\n",
    "\\frac{1}{K}\\sum^{K}_{k=1}(\\frac{\\beta_{f_{j},x(j),k}}{\\beta_{f_{j},x(j)}}-\\frac{\\beta_{f_{j},y(j),k}}{\\beta_{f_{j},y(j)}})\\qquad if\\enspace f_{j} \\in F\\enspace is\\enspace nominal\\\\\n",
    "(\\frac{x(j) - y(j)}{max_{j}-min_{j}})^{2}\\qquad \\qquad \\qquad \\qquad if\\enspace f_{j} \\in F\\enspace is\\enspace numeric\n",
    "\\end{cases}$$\n",
    "\n",
    "where $\\beta_{f_{j},x(j)}$ is the number of instances that have value $x(j)$ for feature $f_{j}$, and $\\beta_{f_{j},x(j),k}$ denotes the number of instances that have value $x_{j}$ for feature $f_{j}$ and output class $k$. In other words, HVDM measures the correlation between a feature and a decision class.\n",
    "\n",
    "Finally, the following equation portrays the similarity function, which produces values in the $(0,1)$ interval, \n",
    "\n",
    "$$\\phi(x,y) = e^{-\\lambda \\big( d(x,y) \\big)}$$\n",
    "\n",
    "where $\\lambda > 0$ is a user-specified smoothing parameter to avoid saturation problems in which similarity values have low variability even for quite dissimilar instances. We use $\\phi(x,y)$ as similarity function to compute the fuzzy-rough sets as defined by Radzikowska and Kerre (2002). To compute the fuzzy-rough sets as defined by Inuiguchi et al. (2015), $\\phi(x,y)$ is multiplied by the $\\mu_{X_{k}}(x)$ to make sure that we are comparing instances that are similarly classified ($\\mu_{R}(y,x) = \\mu_{X_{k}}(x) \\phi(x,y)$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Bias measure: fuzzy rough uncertainty (FRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FRU measure quantifies how much the absence of the sensitive feature $f_{i}$ modifies the fuzzy rough boundary regions. The difference can be both positive or negative. To quantify these differences, we use the membership values of instances in $U$ to the boundary regions using (i) the full set of features, and (ii) the set of features without the sensitive feature $f_{i}$ (denoted by $\\neg f_{i}$). We use equation \\eqref{eqn:FRU_L2} to compute the FRU value associated with the $k$-th decision class and the $i$-th sensitive feature, \n",
    "\n",
    "${\\Omega}_{k}(f_{i}) = \\sqrt{\\frac{1}{|U|}\\sum_{x \\in U}{(\\Delta_{B_{k}\\neg f_{i}}(x))^2}}$\n",
    "\n",
    "such that $\\Delta_{B_{k}\\neg f_{i}}(x) = \\mu_{B_{k}}(x) - \\mu_{B_{k} \\neg f_{i}}(x)$ when the removal of the $i$-th feature increases or decreases the uncertainty. To lighten the notation, we denote the $k$-th boundary region $\\mu_{BND(X_{k})}(x)$ with $\\mu_{B_{k}}(x)$. It is also possible to divide the FRU by the sum of the FRU values of all features in the dataset, $\\Omega_{k}(f_{i}) / \\sum_{j}\\Omega_k(f_j)$, such that the FRU values add up to one which makes their interpretation more meaningful. Overall, the proposed granular measure is similar to computing the relevance of the sensitive feature to preserve the decision boundaries attached to the problem. Note that in multiclass classification problems, the final FRU measure is the average FRU value of all decision classes if we normalize by their fuzzy cardinalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FRU can also capture group fairness by quantifying the change in fuzzy rough boundary regions for the members of a group within a sensitive feature. We refer to this variant of the FRU as group-FRU. To quantify the changes in the boundary values per group, we divide the universe of discourse into a $G_j$ partition that consists of the instances of the $j$-th group in the sensitive feature $f_{i}$ for the $k$-th decision class. This implies that the sensitive feature $f_i$ is nominal and contains $\\{2,..,p\\}$ group-categories (such as females or males for the feature sex). The equation below computes the FRU value associated with a group $j$ of the $i$-th sensitive feature for the $k$-th decision class.  \n",
    "\n",
    "$\\Omega_{k,j}(f_{i}) = \\sqrt{\\frac{1}{|G_{j}|}\\sum_{x \\in G_{j}}{(\\Delta_{B_{k}\\neg f_{i}}(x))^2}}$  \n",
    "\n",
    "Note that dividing with the total number of instances of group $j$ allows comparing groups of different sizes. We assume that the decision-making process is fair for all groups if their FRU values are similar. It is also possible to divide by the sum of all group-FRU values, $\\widetilde{\\Omega}_{k,j}(f_{i})=\\Omega_{k,j}(f_{i}) / \\sum_{p}\\Omega_{k,p}(f_i)$, such that both add up to one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithms & computational performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first algorithm we create can be found below. It used loops which makes is relatively slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FRS_loop:\n",
    "    '''\n",
    "    Slower version of the algorithm, loops through everything, kept it for validation reasons\n",
    "    '''\n",
    "\n",
    "    def __init__(self, dataset, a, im, con, frs_method, decision_class = None, fuzzy_decision_class = False):\n",
    "        '''\n",
    "        Initialized objects\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha: float\n",
    "            float between 0 and 1, parameter that separates the fuzzy-rough regions\n",
    "        implication: string\n",
    "            options are 'Luka', 'Godel', 'Fodor', 'Goguen'\n",
    "        conjunction: string\n",
    "            options are 'Standard', 'Algebraic', 'Luka', 'Drastic'\n",
    "            choose 'radzikowska', 'inuiguchi' definition of fuzzy-rough sets\n",
    "        '''\n",
    "        self.X = dataset\n",
    "        self.D = None\n",
    "        self.im = im\n",
    "        self.con = con\n",
    "        self.p_att = None\n",
    "        self.a = a\n",
    "        self.frs_method = frs_method\n",
    "        self.decision_class = decision_class\n",
    "        self.fdc = fuzzy_decision_class\n",
    "\n",
    "    def regions(self):\n",
    "        \n",
    "        # if no decision class is specified, then all will be computed\n",
    "        if self.decision_class == None:\n",
    "            self.D = np.unique(self.X[:,-1])\n",
    "\n",
    "        # if a decision class is specified\n",
    "        if self.decision_class != None:\n",
    "            self.D = np.array([self.decision_class])\n",
    "\n",
    "        POS = np.zeros((len(self.D), len(self.X)))\n",
    "        NEG = np.zeros((len(self.D), len(self.X)))\n",
    "        BND = np.zeros((len(self.D), len(self.X)))\n",
    "        \n",
    "        for k, k_idx in zip(self.D, range(len(self.D))):\n",
    "            for idx in range(len(self.X)):\n",
    "                if self.frs_method == 'radzikowska':\n",
    "                    POS[k_idx][idx], NEG[k_idx][idx], BND[k_idx][idx] = self.process_object_radzikowska(idx, k)\n",
    "                if self.frs_method == 'inuiguchi':\n",
    "                    POS[k_idx][idx], NEG[k_idx][idx], BND[k_idx][idx] = self.process_object_inuiguchi(idx, k)\n",
    "        return [POS, NEG, BND]\n",
    "\n",
    "    def process_object_radzikowska(self, idx, k):\n",
    "        \n",
    "        inf = 1\n",
    "        sup = 0\n",
    "\n",
    "        x = self.X[idx,:]\n",
    "\n",
    "        for y in self.X:\n",
    "            inf = min(inf, self.implicator(self.similarity(y, x), self.membership(y, k)))\n",
    "            sup = max(sup, self.conjunction(self.similarity(y, x), self.membership(y, k)))\n",
    "\n",
    "        return [inf, 1-sup, sup-inf]\n",
    "    \n",
    "    \n",
    "    def process_object_inuiguchi(self, idx, k):\n",
    "\n",
    "        inf = 1\n",
    "        sup = 0\n",
    "\n",
    "        x = self.X[idx,:]\n",
    "\n",
    "        for y in self.X:\n",
    "            inf = min(inf, self.implicator(self.similarity(y, x), self.membership(y, k)))\n",
    "            sup = max(sup, self.conjunction(self.similarity(y, x), self.membership(y, k)))\n",
    "\n",
    "        inf = min(inf, self.membership(x, k))\n",
    "        sup = max(sup, self.membership(x, k))\n",
    "\n",
    "        return [inf, 1-sup, sup-inf] \n",
    "    \n",
    "    def similarity(self, x, y):\n",
    "\n",
    "        distance = 0\n",
    "        for i in range(len(x)-1):\n",
    "\n",
    "            if self.p_att == i:\n",
    "                continue\n",
    "\n",
    "            if numeric[i]:\n",
    "                distance += abs(x[i] - y[i])\n",
    "            else:\n",
    "                distance += 1.0 if (x[i] != y[i]) else 0.0\n",
    "\n",
    "        # the coefficient must be adjusted per dataset\n",
    "        return np.exp(-self.a * distance)\n",
    "\n",
    "    def implicator(self, a, b):\n",
    "        if self.im == 'Luka':\n",
    "            return min(1 - a + b, 1)\n",
    "    \n",
    "        if self.im == 'Fodor':\n",
    "            return 1 if a <= b else max(1-a,b)\n",
    "            \n",
    "        if self.im == 'Godel':\n",
    "            return 1 if (a <= b) else b\n",
    "            \n",
    "        if self.im == 'Goguen':\n",
    "            return 1 if a <= b else (b / a)\n",
    "        \n",
    "        if self.im == 'Standard':\n",
    "            return 1 if a <= b else 0\n",
    "        \n",
    "        if self.im == 'Kleene-Dienes':\n",
    "            return max(1-a,b)\n",
    "        \n",
    "        if self.im == 'Zadeh':\n",
    "            return max(1-a,min(a,b))\n",
    "        \n",
    "        if self.im == 'Larsen':\n",
    "            return a*b\n",
    "        \n",
    "        if self.im == 'Mamdani':\n",
    "            return min(a,b)\n",
    "        \n",
    "        if self.im == 'Reichenbach':\n",
    "            return 1 - a + a*b\n",
    "        \n",
    "        if self.im == 'Yager':\n",
    "            return 1 if (a == 0) and (b == 0) else b**a\n",
    "\n",
    "    def conjunction(self, a, b):\n",
    "        if self.con == 'Luka':\n",
    "            return max(a + b - 1, 0)\n",
    "        \n",
    "        if self.con == 'Algebraic':\n",
    "            return a*b\n",
    "        \n",
    "        if self.con == 'Drastic':\n",
    "            if max(a, b) < 1:\n",
    "                return 0\n",
    "            elif a == 1:\n",
    "                return b\n",
    "            else:\n",
    "                return a\n",
    "        \n",
    "        if self.con == 'Standard':\n",
    "            return min(a, b)\n",
    "\n",
    "    def fuzzy_relation_asymetric(self, x, y, k):\n",
    "        return self.membership(x, k) * self.similarity(x, y)\n",
    "\n",
    "    def membership(self, x, k):\n",
    "        if self.fdc:\n",
    "            return x[-1]\n",
    "        # we do not argue about the labeling accuracy\n",
    "        else:\n",
    "            return 1.0 if x[-1] == k else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm was adjusted to work using vectors. This version is faster but requires large memory space to store the similarity matrix. This version of the algorithm has been wrapped in a pypi package, `fairfru` which can be found [in this link](https://pypi.org/project/fairfru/). The code in the package has been adjusted to be able to handle storing large distance matrices using the `tables` and `h5py` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FRS:\n",
    "    '''\n",
    "    Faster function to create the fuzzy-rough sets. Good for datasets up to 1000 instances. Works at an array level.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, \n",
    "                 df, \n",
    "                 target, \n",
    "                 alpha=1.0, \n",
    "                 distance = 'HMOM', \n",
    "                 implication = 'Luka', \n",
    "                 conjunction = 'Luka',\n",
    "                 frs_method = 'Radzikowska'):\n",
    "\n",
    "        '''\n",
    "        Computes the membership values to the fuzzy-rough positive, negative and boundary regions\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        alpha: float\n",
    "            parameter that separates the fuzzy-rough regions\n",
    "        distance: string \n",
    "            'HMOM' (Heterogeneous Manhattan Overlap Distance), 'HEOM' (Heterogeneous Euclidean Overlap Distance), HVDM (Heterogeneous Value Difference Metric)\n",
    "        implication: string\n",
    "            options are 'Luka', 'Godel', 'Fodor', 'Goguen' (see publication for details)\n",
    "        conjunction: string\n",
    "            options are 'Standard', 'Algebraic', 'Luka', 'Drastic' (see publication for details)\n",
    "        frs_method: string\n",
    "            fuzzy-rough set method, can be either 'Radzikowska','Inuiguchi'.\n",
    "        '''\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.data, self.membership, self.numeric, self.nominal = self.preprocess(df, target)\n",
    "        self.distance = distance\n",
    "        self.im = implication\n",
    "        self.con = conjunction\n",
    "        self.frs_method = frs_method\n",
    "        self.K = len(np.unique(self.membership))\n",
    "\n",
    "        if self.distance == 'HVDM':\n",
    "            df = df.reset_index(drop=True)\n",
    "            beta_f_x_k, beta_f_x, nominal_columns = self.nominal_probabilities(df, target)\n",
    "            self.hvdm_nom = self.HVDM_nominal(df, beta_f_x_k, beta_f_x, nominal_columns)\n",
    "        \n",
    "    def preprocess(self, df, target):\n",
    "\n",
    "        df_new = df.copy()\n",
    "        target = df_new.pop(target)\n",
    "        membership = pd.get_dummies(target, dtype='int')\n",
    "        numeric = [False if df_new[col].dtype == 'object' else True for col in df_new]\n",
    "        nominal = [True if df_new[col].dtype == 'object' else False for col in df_new]\n",
    "\n",
    "        return df_new.to_numpy(), membership.to_numpy(), numeric, nominal\n",
    "    \n",
    "    def nominal_probabilities(self,df,target):\n",
    "        beta_f_x_k = {}\n",
    "        beta_f_x = {}\n",
    "\n",
    "        df1 = df.copy()\n",
    "        target_values = df1.pop(target)\n",
    "\n",
    "        # select nominal values and target feature\n",
    "        nom_df = df1[df1.columns[self.nominal]].copy()\n",
    "        nom_df[target] = target_values.values\n",
    "\n",
    "        for i in df1.columns[self.nominal]:\n",
    "            beta_f_x_k[i] = pd.DataFrame(product(list(nom_df[i].unique()), list(nom_df[target].unique())), columns=[i,target])\n",
    "    \n",
    "            # add empty frequency column\n",
    "            beta_f_x_k[i]['frequency'] = np.zeros((len(beta_f_x_k[i])))\n",
    "\n",
    "            # set index\n",
    "            beta_f_x_k[i] = beta_f_x_k[i].set_index([i,target])\n",
    "\n",
    "            # populate frequency column with number of occurances of category x output class\n",
    "            freq_f_k = nom_df[[i,target]].groupby([i,target])[target].count()\n",
    "            for j in range(len(freq_f_k)):\n",
    "                beta_f_x_k[i].loc[(freq_f_k.index[j])] = freq_f_k.iloc[j]\n",
    "            \n",
    "            # number of instances per category in the nominal feature\n",
    "            beta_f_x[i] = nom_df[i].value_counts()\n",
    "        \n",
    "        return beta_f_x_k, beta_f_x, df1.columns[self.nominal]\n",
    "    \n",
    "    def HVDM_nominal(self, df, beta_f_x_k, beta_f_x, nom_cols):\n",
    "        nom_d = np.empty((1,len(nom_cols)+2)) # two extra columns for the indices of x and y\n",
    "        cols = ['x','y']\n",
    "        [cols.append(f) for f in nom_cols]\n",
    "\n",
    "        for x in range(len(df)):\n",
    "            for y in range(len(self.data)):\n",
    "                tau_nominal_F = [x,y]\n",
    "                for f in nom_cols:\n",
    "                    tau_nominal = 0\n",
    "                    for k in range(self.K):\n",
    "                        b_f_x_k = beta_f_x_k[f].loc[(df.loc[x,f],k)].values[0]\n",
    "                        b_f_y_k = beta_f_x_k[f].loc[(df.loc[y,f],k)].values[0]\n",
    "                        b_f_x = beta_f_x[f][df.loc[x,f]]\n",
    "                        b_f_y = beta_f_x[f][df.loc[y,f]]\n",
    "                        tau_nominal = tau_nominal + ((b_f_x_k/b_f_x) - (b_f_y_k/b_f_y))**2\n",
    "                    tau_nominal = (tau_nominal / self.K)\n",
    "                    tau_nominal_F.append(tau_nominal)\n",
    "                nom_d = np.append(nom_d,[tau_nominal_F],axis=0)\n",
    "        nom_d = pd.DataFrame(nom_d[1:],columns=cols) # first row is removed since it was only to initialize\n",
    "        nom_d = nom_d.set_index(['x','y'])\n",
    "\n",
    "        return nom_d\n",
    "\n",
    "    def regions(self):\n",
    "\n",
    "        POS = np.zeros((self.K, len(self.data)))\n",
    "        NEG = np.zeros((self.K, len(self.data)))\n",
    "        BND = np.zeros((self.K, len(self.data)))\n",
    "\n",
    "        rest = pd.DataFrame(columns=['class','x_index', 'y_index', 'sim_x_y','mu_x_k', 'R_x_y_k', 'I_a', 'I', 'min','m_y_k', 'T_a', 'T', 'max', 'R_y_x_k'])\n",
    "        \n",
    "        for i in range(len(self.data)):\n",
    "            distance = self.similarity(i)\n",
    "            for k in np.unique(self.membership):\n",
    "                if self.frs_method == 'Inuiguchi':\n",
    "                    POS[k][i], NEG[k][i], BND[k][i] = self.process_object_inuiguchi(i, k, distance)\n",
    "                if self.frs_method == 'Radzikowska':\n",
    "                    POS[k][i], NEG[k][i], BND[k][i] = self.process_object_radzikowska(i, k, distance)\n",
    "\n",
    "        return [POS, NEG, BND]\n",
    "\n",
    "    def similarity(self, i):\n",
    "        if self.distance == 'HMOM':\n",
    "            d = np.sum(np.abs(np.subtract(self.data[i,self.numeric].T,self.data[:,self.numeric])),axis=1) + np.sum(self.data[i,self.nominal].T != self.data[:,self.nominal],axis=1)\n",
    "        if self.distance == 'HEOM':\n",
    "            d = (np.sum(np.subtract(self.data[i,self.numeric].T,self.data[:,self.numeric])**2,axis=1) + np.sum(self.data[i,self.nominal].T != self.data[:,self.nominal],axis=1))**0.5\n",
    "        if self.distance == 'HVDM':\n",
    "            d = (np.sum(np.subtract(self.data[i,self.numeric].T,self.data[:,self.numeric])**2,axis=1) + np.sum(self.hvdm_nom.loc[i],axis=1))**0.5\n",
    "\n",
    "        return np.exp(-self.alpha * d.astype('float64'))\n",
    "    \n",
    "    def process_object_inuiguchi_symmetric(self, i, k, distance):\n",
    "       \n",
    "        # lower approximation\n",
    "        fuzzy_relation_i_j = distance #  * self.membership[i,k]\n",
    "        fuzzy_implication = self.implicator(fuzzy_relation_i_j, self.membership[:,k])\n",
    "        infinum = min(1, fuzzy_implication)\n",
    "        inf = min(infinum, self.membership[i,k])\n",
    "        \n",
    "        # upper approximation\n",
    "        fuzzy_relation_j_i = distance # * self.membership[:,k]\n",
    "        fuzzy_conjunction = self.conjunction(fuzzy_relation_j_i, self.membership[:,k])\n",
    "        supremum = max(0, fuzzy_conjunction)\n",
    "        sup = max(supremum, self.membership[i,k])\n",
    "        \n",
    "        return inf, 1-sup, sup-inf\n",
    "    \n",
    "    def process_object_radzikowska(self, i, k, distance):\n",
    "        \n",
    "        # lower approximation\n",
    "        fuzzy_implication = self.implicator(distance, self.membership[:,k])\n",
    "        inf = min(1, fuzzy_implication)\n",
    "        \n",
    "        # upper approximation\n",
    "        fuzzy_conjunction = self.conjunction(distance, self.membership[:,k])\n",
    "        sup = max(0, fuzzy_conjunction)\n",
    "\n",
    "        return inf, 1-sup, sup-inf\n",
    "\n",
    "    def implicator(self, a, b):\n",
    "\n",
    "        if self.im == 'Luka':\n",
    "            return min(np.min(1 - a + b),1)\n",
    "        \n",
    "        if self.im == 'Fodor':\n",
    "            return min(np.where(a <= b, 1, np.maximum(1-a,b)))\n",
    "\n",
    "        if self.im == 'Godel':\n",
    "            return min(np.where(a <= b, 1, b))\n",
    "        \n",
    "        if self.im == 'Goguen':\n",
    "            from numpy import inf\n",
    "            goguen = np.where(a <= b, 1, b/a)\n",
    "            goguen[goguen == inf] = 0\n",
    "            return min(goguen)\n",
    "        \n",
    "        if self.im == 'Standard':\n",
    "            return min(np.where(a <= b, 1, 0))\n",
    "        \n",
    "        if self.im == 'Kleene-Dienes':\n",
    "            return min(np.maximum(1 - a, b))\n",
    "\n",
    "        if self.im == 'Zadeh':\n",
    "            return min(np.maximum(1-a, np.minimum(a, b)))\n",
    "        \n",
    "        if self.im == 'Larsen':\n",
    "            return min(a*b)\n",
    "        \n",
    "        if self.im == 'Mamdani':\n",
    "            return min(np.minimum(a,b))\n",
    "        \n",
    "        if self.im == 'Reichenbach':\n",
    "            return min(1 - a + a*b)\n",
    "        \n",
    "        if self.im == 'Yager':\n",
    "            return min(np.where(np.logical_and(a == 0, b == 0), 1, a*b))\n",
    "\n",
    "    def conjunction(self, a, b):\n",
    "        \n",
    "        if self.con == 'Luka':\n",
    "            return max(np.max(a + b - 1), 0)\n",
    "        \n",
    "        if self.con == 'Standard':\n",
    "            return max(np.minimum(a,b))\n",
    "        \n",
    "        if self.con == 'Drastic':\n",
    "            return max(np.maximum(np.where(b==1, a, 0),np.where(a==1, b, 0)))\n",
    "        \n",
    "        if self.con == 'Algebraic':\n",
    "            return max(a*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Compare algorithm loop with vector version & computation speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the synthetic dataset we used the framework of Bauman et al. (2023, Bias on Demand: A Modelling Framework That Generates Synthetic Data With Bias). The vector implementation is obviously faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop implementation 545.4065527915955 s\n"
     ]
    }
   ],
   "source": [
    "# loop implementation\n",
    "param_dic = {\"dim\":10000, \"l_y\":0, \"l_m_y\":0, \"thr_supp\":1, \"l_h_r\":1.5,  \"l_h_q\":0,\n",
    "                \"l_m\":0, \"p_u\":0.3, \"l_r\":True, \"l_o\":False, \"l_y_b\":0,\n",
    "                \"l_q\":2, \"sy\":2, \"l_r_q\":0, \"seed\":42, \"dataset_name\": None}\n",
    "\n",
    "X, y, _, _, _, _, _, _, _, _, _, _, _, poped, metadata = create_synth(**param_dic)\n",
    "X['y'] = y\n",
    "Z = X.values\n",
    "\n",
    "# choose an implicator: 'Luka', 'Godel', 'Fodor', 'Goguen'\n",
    "# choose a conjunction: 'Standard', 'Algebraic', 'Luka', 'Drastic'\n",
    "numeric = [True, False, False]\n",
    "start = time.time()\n",
    "POS_l, NEG_l, BND_l = FRS_loop(Z, 0.5, 'Luka', 'Luka', 'radzikowska').regions()\n",
    "end = time.time()\n",
    "print('Loop implementation', end - start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop implementation 11.762163162231445\n"
     ]
    }
   ],
   "source": [
    "# vector implementation\n",
    "param_dic = {\"dim\":10000, \"l_y\":0, \"l_m_y\":0, \"thr_supp\":1, \"l_h_r\":1.5,  \"l_h_q\":0,\n",
    "                \"l_m\":0, \"p_u\":0.3, \"l_r\":True, \"l_o\":False, \"l_y_b\":0,\n",
    "                \"l_q\":2, \"sy\":2, \"l_r_q\":0, \"seed\":42, \"dataset_name\": None}\n",
    "X, y, _, _, _, _, _, _, _, _, _, _, _, poped, metadata = create_synth(**param_dic)\n",
    "X['y'] = y\n",
    "Z = X.values\n",
    "\n",
    "# choose an implicator: 'Luka', 'Godel', 'Fodor', 'Goguen'\n",
    "# choose a conjunction: 'Standard', 'Algebraic', 'Luka', 'Drastic'\n",
    "numeric = [True, False, False]\n",
    "start = time.time()\n",
    "POS_v, NEG_v, BND_v = membership_values_vectors = FRS(X, 'y', alpha=0.5, distance = 'HMOM', implication = 'Fodor', conjunction = 'Luka').regions()\n",
    "end = time.time()\n",
    "print('Loop implementation', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we observe performance as the size of the dataset increases. It is obvious that the increase is not linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedim = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in np.arange(20,2000,10): \n",
    "    # choose the parameters to create the synthetic dataset using \n",
    "    param_dic = {\"dim\":d, \"l_y\":0, \"l_m_y\":0, \"thr_supp\":1, \"l_h_r\":1.5,  \"l_h_q\":0,\n",
    "                \"l_m\":0, \"p_u\":0.3, \"l_r\":True, \"l_o\":False, \"l_y_b\":0,\n",
    "                \"l_q\":2, \"sy\":2, \"l_r_q\":0, \"seed\":42, \"dataset_name\": None}\n",
    "    \n",
    "    # vector implementation\n",
    "    X, y, _, _, _, _, _, _, _, _, _, _, _, poped, metadata = create_synth(**param_dic)\n",
    "    X['y'] = y\n",
    "    Z = X.values\n",
    "\n",
    "    # choose an implicator: 'Luka', 'Godel', 'Fodor', 'Goguen'\n",
    "    # choose a conjunction: 'Standard', 'Algebraic', 'Luka', 'Drastic'\n",
    "    numeric = [True, False, False]\n",
    "    start = time.time()\n",
    "    POS_v, NEG_v, BND_v = membership_values_vectors = FRS(X, 'y', alpha=0.5, distance = 'HMOM', implication = 'Fodor', conjunction = 'Luka').regions()\n",
    "    end = time.time()\n",
    "\n",
    "    timedim.append([d, end - start])\n",
    "\n",
    "tdim = pd.DataFrame(timedim, columns=['size','seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "tdim['seconds per size'] = tdim['seconds'] / tdim['size']\n",
    "sns.lineplot(data=tdim,x='size',y='seconds per size')\n",
    "filepath = r\"..\\results\\figures\\FRU\"\n",
    "filename = os.path.join(filepath, 'time_complexity_FRU.pdf')\n",
    "plt.savefig(filename, bbox_inches='tight', dpi=1000, format = 'pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Toy example, thesis section 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfair scenario 1\n",
    "toydf1 = pd.DataFrame([\n",
    "    [0.82, 0.94, 'white', 'admit'],         # high grades, both got it\n",
    "    [0.83, 0.92, 'non-white', 'admit'],     # high grades, both got it\n",
    "    [0.76, 0.85, 'non-white', 'not admit'], # medium grade, black did not get it\n",
    "    [0.76, 0.85, 'white', 'admit'],         # medium grade, white did not get it\n",
    "    [0.74, 0.85, 'non-white', 'not admit'], # medium grade, white got it\n",
    "    [0.74, 0.95, 'white', 'admit'],         # medium grade, white got it - partial inconsistency\n",
    "    [0.56, 0.64, 'non-white', 'not admit'], # low grade, white got it\n",
    "    [0.57, 0.63, 'white', 'not admit']],    # low grade, black did not get it\n",
    "    columns=['LSAT', 'GPA', 'race', 'admit']) \n",
    "toydf1.index = toydf1.index +1\n",
    "unfair = ['fair', 'fair', 'unfair', 'fair', 'unfair', 'fair', 'fair', 'fair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit      race     \n",
       "admit      non-white    0.25\n",
       "           white        0.75\n",
       "not admit  non-white    0.75\n",
       "           white        0.25\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base rates\n",
    "(toydf1.groupby(['admit','race'])['admit'].count() / toydf1.groupby(['admit'])['race'].count()).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = toydf1.copy()\n",
    "toy['admit'] = toy['admit'].replace({'not admit':0, 'admit':1})\n",
    "\n",
    "membership_dictonary = {}\n",
    "numeric = list(toy.dtypes != 'object')\n",
    "membership_dictonary['full'] = FRS_loop(toy.values, 0.5, 'Luka', 'Luka', 'radzikowska').regions()\n",
    "for f in toy.columns[:-1]:\n",
    "    tdf = toy.copy()\n",
    "    tdf.pop(f)\n",
    "    numeric = list(tdf.dtypes != 'object')\n",
    "    membership_dictonary[f] = POS_prot, NEG_prot, BND_prot = FRS_loop(tdf.values, 0.5, 'Luka', 'Luka', 'radzikowska').regions()\n",
    "\n",
    "toy['$\\mu_{B_{k}}(x)$'] = membership_dictonary['full'][-1][0]\n",
    "toy['$\\mu_{B_{k} \\neg f_{i}}(x)$'] = membership_dictonary['race'][-1][0]\n",
    "toy['$\\Delta_{B_{k}\\neg f_{i}}(x)$'] = membership_dictonary['full'][-1][0] - membership_dictonary['race'][-1][0]\n",
    "toy['fair'] = unfair\n",
    "\n",
    "frus = []\n",
    "for f in toy.columns[:3]:\n",
    "    frus.append(((np.sum((membership_dictonary['full'][-1][0] - membership_dictonary[f][-1][0])**2))/len(toy))**0.5)\n",
    "\n",
    "fru_toy = pd.DataFrame(frus).T\n",
    "fru_toy.columns = toy.columns[:3]\n",
    "fru_toy.index = ['FRU']\n",
    "fru_toy.loc['FRU normalized',:] = fru_toy.loc['FRU',:] / fru_toy.loc['FRU',:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSAT</th>\n",
       "      <th>GPA</th>\n",
       "      <th>race</th>\n",
       "      <th>admit</th>\n",
       "      <th>$\\mu_{B_{k}}(x)$</th>\n",
       "      <th>$\\mu_{B_{k} \\neg f_{i}}(x)$</th>\n",
       "      <th>$\\Delta_{B_{k}\\neg f_{i}}(x)$</th>\n",
       "      <th>fair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.94</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755784</td>\n",
       "      <td>0.927743</td>\n",
       "      <td>-0.171960</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.92</td>\n",
       "      <td>non-white</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932394</td>\n",
       "      <td>0.932394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>non-white</td>\n",
       "      <td>0</td>\n",
       "      <td>0.932394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.067606</td>\n",
       "      <td>unfair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.185353</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.85</td>\n",
       "      <td>non-white</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923116</td>\n",
       "      <td>0.990050</td>\n",
       "      <td>-0.066933</td>\n",
       "      <td>unfair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.95</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782705</td>\n",
       "      <td>0.951229</td>\n",
       "      <td>-0.168525</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.64</td>\n",
       "      <td>non-white</td>\n",
       "      <td>0</td>\n",
       "      <td>0.759572</td>\n",
       "      <td>0.814647</td>\n",
       "      <td>-0.055075</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.63</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0.814647</td>\n",
       "      <td>0.814647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LSAT   GPA       race  admit  $\\mu_{B_{k}}(x)$  \\\n",
       "1  0.82  0.94      white      1          0.755784   \n",
       "2  0.83  0.92  non-white      1          0.932394   \n",
       "3  0.76  0.85  non-white      0          0.932394   \n",
       "4  0.76  0.85      white      1          0.814647   \n",
       "5  0.74  0.85  non-white      0          0.923116   \n",
       "6  0.74  0.95      white      1          0.782705   \n",
       "7  0.56  0.64  non-white      0          0.759572   \n",
       "8  0.57  0.63      white      0          0.814647   \n",
       "\n",
       "   $\\mu_{B_{k} \\neg f_{i}}(x)$  $\\Delta_{B_{k}\\neg f_{i}}(x)$    fair  \n",
       "1                     0.927743                      -0.171960    fair  \n",
       "2                     0.932394                       0.000000    fair  \n",
       "3                     1.000000                      -0.067606  unfair  \n",
       "4                     1.000000                      -0.185353    fair  \n",
       "5                     0.990050                      -0.066933  unfair  \n",
       "6                     0.951229                      -0.168525    fair  \n",
       "7                     0.814647                      -0.055075    fair  \n",
       "8                     0.814647                       0.000000    fair  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSAT</th>\n",
       "      <th>GPA</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FRU</th>\n",
       "      <td>0.074326</td>\n",
       "      <td>0.093926</td>\n",
       "      <td>0.114242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRU normalized</th>\n",
       "      <td>0.263107</td>\n",
       "      <td>0.332488</td>\n",
       "      <td>0.404405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    LSAT       GPA      race\n",
       "FRU             0.074326  0.093926  0.114242\n",
       "FRU normalized  0.263107  0.332488  0.404405"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fru_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\lucp11124\\AppData\\Local\\Temp\\ipykernel_20524\\3676967708.py:4: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  delta_group = toy[toy['race'] == group]['$\\Delta_{B_{k}\\neg f_{i}}(x)$']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group-FRU white</th>\n",
       "      <th>group-FRU non-white</th>\n",
       "      <th>group-FRU absolute difference</th>\n",
       "      <th>group-FRU ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>raw values</th>\n",
       "      <td>0.151926</td>\n",
       "      <td>0.054964</td>\n",
       "      <td>0.096963</td>\n",
       "      <td>0.361778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized values</th>\n",
       "      <td>0.734334</td>\n",
       "      <td>0.265666</td>\n",
       "      <td>-0.468669</td>\n",
       "      <td>0.361778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                  group-FRU white  group-FRU non-white  \\\n",
       "raw values                0.151926             0.054964   \n",
       "normalized values         0.734334             0.265666   \n",
       "\n",
       "0                  group-FRU absolute difference  group-FRU ratio  \n",
       "raw values                              0.096963         0.361778  \n",
       "normalized values                      -0.468669         0.361778  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group FRU\n",
    "gFRU = []\n",
    "for group in toy['race'].unique():\n",
    "    delta_group = toy[toy['race'] == group]['$\\Delta_{B_{k}\\neg f_{i}}(x)$']\n",
    "    groupFRU = (np.sum(delta_group**2)/toy['race'].value_counts()[group])**0.5\n",
    "    gFRU.append(['group-FRU '+group,groupFRU])\n",
    "\n",
    "gFRU = pd.DataFrame(gFRU)\n",
    "gFRU = gFRU.set_index(0, drop=True).T\n",
    "gFRU['group-FRU absolute difference'] = abs(gFRU['group-FRU non-white'] - gFRU['group-FRU white'])\n",
    "gFRU['group-FRU ratio'] = gFRU['group-FRU non-white'] / gFRU['group-FRU white']\n",
    "\n",
    "gFRUnorm = list(((gFRU[['group-FRU white', 'group-FRU non-white']] / (gFRU['group-FRU white'] + gFRU['group-FRU non-white']).values[0]).values)[0])\n",
    "gFRUnorm.append(gFRUnorm[1]-gFRUnorm[0])\n",
    "gFRUnorm.append(gFRUnorm[1]/gFRUnorm[0])\n",
    "gFRU.loc[2,:] = gFRUnorm\n",
    "gFRU.index = ['raw values', 'normalized values']\n",
    "gFRU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
